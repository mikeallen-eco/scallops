---
title: "R Notebook"
output: html_document
---
# Packages


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r packages}
set.seed(42)
library(tidyverse)
library(tidybayes)
library(Cairo)
library(here)
library(magrittr)
library(rstan)
library(Matrix)
library(ggridges)
library(rstanarm)
library(spasm)
library(geosphere)
rstan_options(javascript=FALSE)
#install from
# devtools::install_github("danovando/spasm")
#source(here("functions","generate-length-to-age.R")) # from SPASM by D Ovando
```
## Get summer flounder data

Note that we are now pulling in the raw length composition data, and it is for the fall survey only.

```{r data}
rawdat <- read_csv(here("processed-data","fluke_catch_at_length_fall.csv"))

max_lat_observed <- 42
```

## Convert to ages 


Page 58 of SAW 66: In the current work, the NEFSC trawl survey data for 1976-2016 (ages for 2017 were not yet available) were used to estimate growth parameters for males, females, and sexes combined for the full time series and for seven multi-year (generally five year) bins. The full time series data provide parameters for males (n = 19,424) of Linf = 63.9 cm, k = 0.18, with maximum length of 67 cm (age 6) and age of 15 (length 56-57 cm); parameters for females (n = 20,689) of Linf = 80.6 cm, k = 0.18, with maximum length of 82 cm (age 11) and age of 14 (length 76 cm); and **parameters for sexes combined (n = 40,942, including small fish of undetermined sex) of Linf = 83.6, k = 0.14, with maximum age of 15** (Table below, Figure A66).

AF note: not sure how max age should be used

```{r length-age}
# prep length and age data  
Loo = 83.6
k = 0.14


mean_age_from_length <- function(length){
  age = log(1-length/Loo)/-k 
  return(age)
}

# LOOK AT VON BERT TO ADD SIZE AT T0 TO THIS EQUATION # IGNORE
# REPLACE WITH LENGTH_AT_AGE_KEY_DAT 
# MULTIPLY NUMBER OF FISH IN LENGTH BIN BY THE VECTOR OF PROPORTIONS OF AGES AT THAT LENGTH
# IF MAX AGE = 10
# 
mean_length_from_age <- function(age_vector){
  length_vector = (1-exp(-k*age_vector))*Loo
  return(length_vector)
}

rawdat$age <- mean_age_from_length(rawdat$length)

hist(rawdat$age)

# get SUM ages in each patch for estimating age composition (n_p_a_y)
agedat <- rawdat %>% 
  filter(year>=1972) %>% 
  mutate(age_floor = round(age) - 1, # rounding up so we don't have age zero - should start at age 1
         lat_floor = floor(lat)) %>% 
  rowwise() %>% 
  mutate(
    age_floor = min(age_floor, 15)  # this is estimating a small number of super old fish, up to 24 -- I'm reclassifying them as 15 for now based on the stock assessment, is that right?
  ) %>% 
  group_by(year, age_floor, lat_floor) %>% 
  summarise(sum_at_age =sum(number_at_length))

# get MEAN densities in each patch for estimating total abundance (dens_p_y)
densdat <- rawdat %>% 
  filter(year>=1972) %>% 
  mutate(lat_floor=floor(lat)) %>% 
  group_by(year, lat_floor, haulid) %>% 
  mutate(haul_total = sum(number_at_length)) %>% # get the total number of fish in all ages
  group_by(year, lat_floor) %>% 
  summarise(mean_dens = mean(haul_total)) # mean number of fish/haul for that patch and year


# visualize lat band sampling in fall 

lat_pres <- agedat %>% 
  select(lat_floor, year) %>% 
  distinct() %>% 
  mutate(surveyed=TRUE)

expand.grid(year=unique(agedat$year), lat_floor=unique(agedat$lat_floor)) %>% # get all possible band*year combos
  left_join(agedat %>% # get df with just surveyed bands
              select(lat_floor, year) %>% 
              distinct() %>% 
              mutate(surveyed=TRUE)
  ) %>% 
  mutate(surveyed=replace_na(surveyed, FALSE)) %>%  #classify unsurveyed rows as false
  ggplot(aes(x=year, y=lat_floor)) +
  geom_tile(aes(fill=surveyed)) +
  scale_y_continuous(breaks=seq(min(agedat$lat_floor), max(agedat$lat_floor, 1)))
# based on this, let's drop lat bands below 35 and the year 2016

#FLAG
agedat %<>% filter(lat_floor %in% seq(36,40,1), year<2016)
densdat %<>% filter(lat_floor %in% seq(36,40,1), year<2016)

# check that this now means all bands are surveyed in all years 
expand.grid(year=unique(agedat$year), lat_floor=unique(agedat$lat_floor)) %>% # get all possible band*year combos
  left_join(agedat %>% # get df with just surveyed bands
              select(lat_floor, year) %>% 
              distinct() %>% 
              mutate(surveyed=TRUE)
  ) %>% 
  mutate(surveyed=replace_na(surveyed, FALSE)) %>%  #classify unsurveyed rows as false
  ggplot(aes(x=year, y=lat_floor)) +
  geom_tile(aes(fill=surveyed)) +
  scale_y_continuous(breaks=seq(min(agedat$lat_floor), max(agedat$lat_floor, 1)))

```


## Prep for model

```{r modelprep}
# prep patch area 
patchdat <- rawdat %>% 
  select(lat, lon) %>%
  distinct() %>%
  mutate(lat_floor = floor(lat)) %>% 
  group_by(lat_floor) %>% 
  summarise(max_lon=max(lon),
         min_lon=min(lon)) %>% 
  rowwise() %>% 
  mutate(lon_dist = distGeo(p1=c(max_lon, lat_floor+0.5), p2=c(min_lon, lat_floor+0.5))/1000, # get distance between the furthest longitudes in km, at the midpoint of the lat band 
         patch_area_km2 = lon_dist * 111) %>%  # 1 degree latitude = 111 km 
  select(lat_floor, patch_area_km2) %>% 
  filter(lat_floor %in% agedat$lat_floor) %>% 
  ungroup() %>% 
  mutate(patch = as.integer(as.factor(lat_floor)))
  
## get time dimension
years <- sort(unique(agedat$year)) 
ny <- length(years)
years_train <- ny-10
years_proj <- 10

#get other dimensions
patches <- sort(unique(agedat$lat_floor))
np = length(patches) 
ages <- sort(unique(agedat$age_floor))
n_ages <- length(ages) 
lbins <- sort(unique(rawdat$length))
n_lbins <- length(lbins) 


# make length-at-age key 
length_at_age_key_dat <- spasm::generate_length_at_age_key(
  min_age = min(ages), 
  max_age = max(ages), 
  cv = 0.2, # "magic number" - revisit this sometime (use LIME as a guide?)
  k = k, 
  linf = Loo,
  t0 = 0, # is this right?
  time_step = 1,
  linf_buffer = 1 # doing this just to shoehorn it into the right size for the model; can make it bigger if we need to
)

mean_length_at_age <- map(ages,mean_length_from_age) %>% unlist()

# convert to matrix 
length_at_age_key <- as.matrix(with(length_at_age_key_dat, sparseMatrix(age, length_bin, x=p_bin, index1 = FALSE))) # index1 deals with the fact that indices start at 0 not 1

# make temperature matrix
sbtdat <- rawdat %>% 
  mutate(lat_floor = floor(lat)) %>% 
  filter(lat_floor %in% unique(agedat$lat_floor),
         year %in% unique(agedat$year)) %>% # only use lat bands in the trimmed age data
  group_by(lat_floor, year) %>% 
  summarise(sbt=mean(btemp, na.rm=TRUE)) %>% 
  ungroup() %>% 
  mutate(patch= as.integer(as.factor(lat_floor)), 
         year=as.integer(as.factor(year))) %>% #change real values to indices
  select(-lat_floor)

sbtdat$sbt[is.na(sbtdat$sbt)] <- mean(sbtdat$sbt, na.rm = TRUE)

sbt <- as.matrix(with(sbtdat, sparseMatrix(patch, year, x=sbt))) # visually inspect this to be sure there are no zeroes -- they occur early in the time-series and also in 2016, but the data trimming should have taken care of it

# make population matrices

# add indices
agedat$patch <- as.integer(as.factor(agedat$lat_floor))
agedat$year <- as.integer(as.factor(agedat$year)) 

densdat$patch <- as.integer(as.factor(densdat$lat_floor))
densdat$year <- as.integer(as.factor(densdat$year)) 

# fill in matrix
pop <- array(NA, dim = c(np, n_ages, ny)) 
for(p in 1:np){
  for(a in 1:n_ages){
    for(y in 1:ny){
      tmp <- agedat %>% filter(patch==p, age_floor==(a-1), year==y) # here's where we convert ages to be indexed starting at 1 not 0 for ease in Stan
      pop[p,a,y] <- tmp$sum_at_age
    }
  }
}

dens <- array(NA, dim = c(np, ny)) 

densdat <-  densdat %>% 
  left_join(patchdat) %>% 
  mutate(mean_dens = mean_dens * patch_area_km2)

for(p in 1:np){
  for(y in 1:ny){
    tmp2 <- densdat %>% filter(patch==p, year==y)
    dens[p,y] <- tmp2$mean_dens
  }
}

# mortality
m = 0.25
f = 0.334
z = exp(-m-f)

# dispersal
age_at_maturity = 2
```

## fit a model

```{r fit-model, echo=FALSE, message=FALSE, results="hide"}
age_data <- list(
  np=np,
  n_ages=n_ages,
  ny_train=years_train,
  n_p_a_y = round(pop[,,1:years_train] / 10), 
  abund_p_y = dens[,1:years_train],
  proj_init = pop[,,(years_train+1)],
  ny_proj = years_proj,
  sst = sbt[, 1:years_train], # change these variable names sometime...
  sst_proj = sbt[, (years_train+1):ny],
  z=z,
  k=k,
  loo=Loo,
  length_50_sel_guess=20, # THIS IS A RANDOM GUESS, I can't find help in the stock assessment
  n_lbins = n_lbins, 
  mean_length_at_age = mean_length_at_age, 
  length_at_age_key = length_at_age_key[, 11:84], # DANGER! I'm ignoring the first 10 rows here to make it the same dimensions as n_lbins, just to get it to run, but recognizing that we need to deal with very small fish in the model 
  age_sel = 0,
  bin_mids=lbins+0.5, # also not sure if this is the right way to calculate the midpoints
  sel_100 = 3, # not sure if this should be 2 or 3. it's age 2, but it's the third age category because we start at 0, which I think Stan will classify as 3...?
  age_at_maturity = age_at_maturity,
  patcharea = patchdat$patch_area_km2
)
warmups <- 2000
total_iterations <- 4000
max_treedepth <-  12
n_chains <-  4
n_cores <- 4 
age_model_fit <- stan(file = here::here("src","T_dep_rec_age_str_fluke.stan"), # check that it's the right model!
                      data = age_data,
                      chains = 4,
                      warmup = 5000,
                      iter = 10000,
                      cores = 4,
                      refresh = 250,
                      control = list(max_treedepth = max_treedepth,
                                     adapt_delta = 0.95)
)
```


## evaluate the model

```{r}
  launch_shinystan(age_model_fit)
check_divergences(age_model_fit)
plot(age_model_fit)

# get estimate of true states / posterior predictive / forecast
n_p_a_y_hat <-  tidybayes::gather_draws(age_model_fit, n_p_a_y_hat[patch, age,year], n = 1000)
dens_p_y_hat <-  tidybayes::gather_draws(age_model_fit, dens_p_y_hat[patch,year], n = 1000)

# pp_n_p_a_y_hat <-  tidybayes::gather_draws(age_model_fit, pp_n_p_a_y_hat[patch, age,year], n = 1000) # add this back into the model!

pp_proj_n_p_a_y_hat <-  tidybayes::gather_draws(age_model_fit, pp_proj_n_p_a_y_hat[patch, age,year], n = 1000)

# get real data
n_p_a_y <- pop[,,1:years_train] %>% 
  reshape::melt(varnames = c("patch","age","year")) %>% 
  as_tibble() 
n_p_a_y_proj <- pop[,,(years_train+1):ny] %>% 
  reshape::melt(varnames = c("patch","age","year")) %>% 
  as_tibble() 

# get estimated selectivity at age
sel_at_age <- gather_draws(age_model_fit, mean_selectivity_at_age[age], n=1000)

# calculate means, for transforming the model estimate into the same "units" as our raw data (selected by survey)
sel <- sel_at_age %>% 
  group_by(age) %>% 
  summarise(sel = mean(.value))

# plot trends in abundance by patch (all ages)
gg_dens_p_y_hat <- dens_p_y_hat %>% 
  # filter(patch == 5, year %in% 1:years_train) %>% 
    left_join(patchdat, by="patch") %>% 
ggplot() +
  stat_lineribbon(aes(x = year, y = (.value)),.width = c(.99, .95, .8, .5), color = "red") + # CHECK SCALING
  geom_point(data = densdat, aes(x=year, y= (mean_dens)), size = 2,alpha = 0.5) +
  facet_wrap(~patch, scales="free_y") + 
  scale_fill_brewer() +
  labs(title="model predictions")

gg_dens_check <- dens_p_y_hat %>% 
    left_join(patchdat, by="patch") %>% 
ggplot() +
  stat_lineribbon(aes(x = year, y = .value/max(.value)),.width = c(.99, .95, .8, .5), color = "red") + # CHECK SCALING
  geom_point(data = densdat, aes(x=year, y=mean_dens/max(mean_dens)), size = 2,alpha = 0.5) + 
  facet_wrap(~patch, scales="free_y") + 
  scale_fill_brewer() +
  labs(title="model predictions")

n_p_a_y_hat_prop <- n_p_a_y_hat %>% 
      left_join(sel, by = "age") %>% 
mutate(.valuesel = .value*sel) %>% 
  group_by(patch, year, .iteration) %>% 
  mutate(prop = .valuesel / sum(.valuesel)) %>% 
  ungroup()

tmp3 <- n_p_a_y_hat_prop %>%
  filter(patch == 5, age < 10) %>%
  ggplot() +
  stat_lineribbon(aes(x = age, y = prop),
                  .width = c(.99, .95, .8, .5),
                  color = "red") +
  geom_point(
    data = n_p_a_y %>% group_by(patch, year) %>% mutate(prop = value / sum(value)) %>% ungroup() %>% filter(patch ==
                                                                                                              5),
    aes(x = age, y = prop),
    size = 2,
    alpha = 0.5
  ) +
  facet_wrap( ~ year) 

n_p_a_y_hat_prop %>%
  # left_join(sel, by = 'age') %>% 
  group_by(year, age, patch) %>%
  summarise(n = mean(.value * sel)) %>% 
  group_by(year, patch) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup() %>% 
  filter(age < 10, patch == 5) %>% 
  ggplot(aes(age, y = year, group = year, height = prop)) + 
  geom_density_ridges(stat = "identity") +
  facet_wrap(~patch)

tmp5 <- n_p_a_y_hat_prop %>% 
  filter(patch==5) %>% 
  ggplot() +
  stat_lineribbon(aes(x = age, y = prop),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_a_y %>% group_by(patch, year) %>% mutate(prop = value / sum(value)) %>% ungroup() %>% filter(patch==5), aes(x=age, y=prop), size = 2,alpha = 0.5) + 
  facet_wrap(~year) 

a = n_p_a_y %>% 
  group_by(patch, year) %>% 
  mutate(prop = value / sum(value)) %>% 
  ungroup() %>% 
  filter(age < 10, patch == 5) %>%  
  ggplot(aes(x = age, y = year, group = year, height = prop)) + 
  geom_density_ridges(stat = "identity") + 
  facet_wrap(~patch)

rawdat %>% 
  mutate(lat_floor = floor(lat)) %>% 
  group_by(year, length,lat_floor) %>% 
  summarise(n = sum(number_at_length)) %>% 
  group_by(lat_floor, year) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup() %>% 
  filter(between(lat_floor, 37, 41), year > 2000) %>% 
  ggplot(aes(x = length, y = year, group = year, height = prop)) + 
  geom_density_ridges(stat = "identity") + 
  facet_wrap(~lat_floor)



gg_n_p_a_y_hat_ex <- n_p_a_y_hat %>% 
  left_join(sel, by = "age") %>% 
  filter(patch==3) %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel, group=age),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_a_y, aes(x=year, y=value, group=age), size = 2,alpha = 0.5) + 
  facet_wrap(~age, scales="free_y", ncol=8) + 
  scale_fill_brewer() +
  labs(title="model predictions", x="year", y="count")

gg_n_p_a_y_hat_ex <- n_p_a_y_hat %>% 
  left_join(sel, by = "age") %>% 
  filter(patch==3) %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel, group=age),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_a_y, aes(x=year, y=value, group=age), size = 2,alpha = 0.5) + 
  facet_wrap(~age, scales="free_y", ncol=8) + 
  scale_fill_brewer() +
  labs(title="model predictions", x="year", y="count")
ggsave(gg_n_p_a_y_hat_ex, filename=here("results","fluke_pred_patch_6.png"), width=10, height=4, dpi=300)

gg_n_p_a_y_hat_age_2 <- n_p_a_y_hat %>% 
  left_join(sel, by = "age") %>% 
  filter(age==2) %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_a_y %>% filter(age==2), aes(x=year, y=value), size = 2,alpha = 0.5) + 
  facet_wrap(~patch, scales="free_y") + 
  scale_fill_brewer() +
  labs(title="age 2")


# posterior predictive fits
# gg_pp_n_p_a_y_hat <- pp_n_p_a_y_hat %>% 
#   ggplot() +
#   stat_lineribbon(aes(x = year, y = .value, group=age),.width = c(.99, .95, .8, .5), color = "red") +
#   geom_point(data = n_p_a_y, aes(x=year, y=value, group=age), size = 2,alpha = 0.5) + 
#     scale_y_continuous(limits=c(0,500)) + # changed from free scales to constrain y-axis
# facet_grid(patch~age) + 
#   scale_fill_brewer()+
#   labs(title="posterior predictive fit")

# forecast fits
gg_pp_proj_n_p_a_y_hat <- pp_proj_n_p_a_y_hat %>%
  left_join(sel, by = "age") %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel, group=age),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_a_y_proj, aes(x=year, y=value, group=age), size = 2,alpha = 0.5) +
  #scale_y_continuous(limits=c(0,200)) + # changed from free scales to constrain y-axis
  facet_grid(age~patch, scales="free_y") + 
  scale_fill_brewer() +
  labs(title="forecast")

gg_pp_proj_n_p_a_y_hat_ex <- pp_proj_n_p_a_y_hat %>%
  left_join(sel, by = "age") %>% 
  filter(patch==6) %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel, group=age),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_a_y_proj, aes(x=year, y=value, group=age), size = 2,alpha = 0.5) +
  scale_y_continuous(limits=c(0,200)) + # changed from free scales to constrain y-axis
  facet_wrap(~age, ncol=8, scales="free_y") + 
  scale_fill_brewer() +
  labs(title="forecast", x="year", y="count")
ggsave(gg_pp_proj_n_p_a_y_hat_ex, filename=here("results","fluke_forecast_patch_6.png"), width=10, height=4, dpi=300)

gg_n_p_a_y_hat
#gg_pp_n_p_a_y_hat
gg_pp_proj_n_p_a_y_hat

ggsave(gg_n_p_a_y_hat, filename=here("results","fluke_age_structure_model_predictions.png"), scale=1.5, width=6, height=10)
ggsave(gg_pp_proj_n_p_a_y_hat, filename=here("results","fluke_age_structure_forecast.png"), scale=1.5, width=6, height=10)

```


```{r summary}
n_p_a_y_hat_summary <- n_p_a_y_hat %>% 
  group_by(.draw) %>% 
  mutate(meanval = mean(.value)) %>% # get mean at each draw position across all chains
  ungroup() %>% 
  group_by(patch, age, year) %>% 
  summarise(
    mean_n = mean(.value), 
    median_n = median(.value),
    lower_n = quantile(.value, 0.05),
    upper_n = quantile(.value, 0.95)
  )

gg_abund_ind <- n_p_a_y_hat_summary %>% 
  group_by(year) %>% 
  mutate(sum_n = sum(mean_n)) %>% 
  ungroup() %>% 
  ggplot() + 
  geom_line(aes(x=year, y=sum_n))

```



## Fit one-patch model

```{r fit-one-patch-model, echo=FALSE, message=FALSE}

pop2 <- array(NA, dim = c(n_ages, ny)) 
for(a in 1:n_ages){
  for(y in 1:ny){
    tmp <- agedat %>% filter(age_floor==(a-1), year==y) %>% 
      summarise(sum_number_at_age = sum(number_at_age))
    pop2[a,y] <- tmp$sum_number_at_age
  }
}

one_patch_data <- list(
  np=np,
  n_ages=n_ages,
  ny_train=years_train,
  n_a_y = pop2[,1:years_train], 
  proj_init = pop2[,1],
  ny_proj = years_proj,
  sst = sbtdat %>% group_by(year) %>% summarise(meansbt = mean(sbt)) %>% filter(year <= years_train) %>% pull(meansbt),
  sst_proj = sbtdat %>% group_by(year) %>% summarise(meansbt = mean(sbt)) %>% filter(year > years_train) %>% pull(meansbt),
  z=z,
  k=k,
  loo=Loo,
  length_50_sel_guess=20, # THIS IS A RANDOM GUESS, I can't find help in the stock assessment
  n_lbins = n_lbins, 
  mean_length_at_age = mean_length_at_age, 
  length_at_age_key = length_at_age_key[, 11:84], # DANGER! I'm ignoring the first 10 rows here to make it the same dimensions as n_lbins, just to get it to run, but recognizing that we need to deal with very small fish in the model 
  age_sel = 0,
  bin_mids=lbins+0.5, # also not sure if this is the right way to calculate the midpoints
  sel_100 = 3 # not sure if this should be 2 or 3. it's age 2, but it's the third age category because we start at 0, which I think Stan will classify as 3...?
)

warmups <- 2000

total_iterations <- 4000

max_treedepth <-  12

n_chains <-  4

n_cores <- 4 

one_patch_model_fit <- stan(file = here::here("src","T_dep_rec_age_str_fluke_one_patch.stan"), # check that it's the right model!
                            data = one_patch_data,
                            chains = 1,
                            warmup = warmups,
                            iter = total_iterations,
                            cores = 1,
                            refresh = 250,
                            control = list(max_treedepth = max_treedepth,
                                           adapt_delta = 0.95)
)

```
## Evaluate one-patch model
```{r}
#launch_shinystan(one_patch_model_fit)
check_divergences(one_patch_model_fit)
plot(one_patch_model_fit)

# get estimate of true states / posterior predictive / forecast
n_a_y_hat <-  tidybayes::gather_draws(one_patch_model_fit
                                      , n_a_y_hat[age,year], n = 1000)

# pp_n_p_a_y_hat <-  tidybayes::gather_draws(age_model_fit, pp_n_p_a_y_hat[patch, age,year], n = 1000) # add this back into the model!

pp_proj_n_a_y_hat <-  tidybayes::gather_draws(one_patch_model_fit, pp_proj_n_a_y_hat[ age,year], n = 1000)


# get real data
n_a_y <- pop2[,1:years_train] %>% 
  reshape::melt(varnames = c("age","year")) %>% 
  as_tibble() 
n_a_y_proj <- pop2[,(years_train+1):ny] %>% 
  reshape::melt(varnames = c("age","year")) %>% 
  as_tibble() 

# get estimated selectivity at age
sel_at_age <- gather_draws(one_patch_model_fit, mean_selectivity_at_age[age], n=1000)

# get detection probability
theta_est <- gather_draws(one_patch_model_fit, theta, n=1000)

# calculate means, for transforming the model estimate into the same "units" as our raw data (selected by survey)
sel <- sel_at_age %>% 
  group_by(age) %>% 
  summarise(sel = mean(.value))

gg_n_a_y_hat <- n_a_y_hat %>% 
  left_join(sel, by = "age") %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel, group=age),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_a_y, aes(x=year, y=value, group=age), size = 2,alpha = 0.5) + 
  facet_wrap(~age, scales="free_y") + 
  scale_fill_brewer() +
  labs(title="model predictions")

# forecast fits
gg_pp_proj_n_a_y_hat <- pp_proj_n_a_y_hat %>%
  left_join(sel, by = "age") %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel, group=age),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_a_y_proj, aes(x=year, y=value, group=age), size = 2,alpha = 0.5) +
  scale_y_continuous(limits=c(0,200)) + # changed from free scales to constrain y-axis
  facet_wrap(~age, scales="free_y") + 
  scale_fill_brewer() +
  labs(title="forecast")


gg_n_a_y_hat
#gg_pp_n_p_a_y_hat
gg_pp_proj_n_a_y_hat

ggsave(gg_n_a_y_hat, filename=here("results","fluke_one_patch_age_structure_model_predictions.png"), scale=1.1, width=10, height=10)
ggsave(gg_pp_proj_n_a_y_hat, filename=here("results","fluke_one_patch_age_structure_forecast.png"), scale=1.1, width=10, height=10)

```
# HERE BEGINS DAN'S OLD CODE

explore data 

```{r explore-data}


flukepop %>% 
  group_by(patch) %>% 
  mutate(scount = count / max(count)) %>% 
  ungroup() %>% 
  # filter(year > 40, patch == 4) %>% 
  ggplot(aes(stage,scount, fill = factor(patch))) + 
  geom_col(position = "dodge") + 
  facet_wrap(~year)


flukepop %>% 
  group_by(stage) %>% 
  summarise(missing = mean(count == 0))

flukepop %>% 
  group_by(year,patch) %>% 
  summarise(hmm = (count[stage ==3] == 0 & sum(count) > 0))

```
# New Model Idea

Use stage 3 to scale the population, fir to the absolute numbers in 3, and back out the recruits. 

Two if statements, if there are any stage comps, and if there are any stage 3s

Let's keep it simple and say that if no stage 3 individuals are observed, nothing is observed, to avoid a weird edge case where some fish are seen, but no stage 3 are seen. Will need to revist this as the data change

So what's the observation model? Probably something like temperature plus a patch fixed effect

```{r}
a <- flukepop %>% 
  group_by(year, patch) %>% 
  summarise(seen = count[stage == 3] > 0,
            numbers = sum(count))

sbt_frame <- sbt %>% 
  as.data.frame() %>% 
  mutate(patch = 1:nrow(.)) %>% 
  pivot_longer(-patch, names_to = "year", values_to = "sbt", names_prefix = "V") %>% 
  mutate(year = as.integer(year))

a <- a %>% 
  left_join(sbt_frame, by = c("year","patch")) %>% 
  group_by(patch) %>% 
  mutate(centered_numbers = numbers - mean(numbers)) %>% 
  group_by(patch) %>% 
  arrange(patch,year) %>% 
  mutate(delta_sbt = sbt - lag(sbt,2),
         delta_numbers = numbers - lag(numbers,1))

mean(a$seen)

a %>% 
  ggplot(aes(sbt, numbers)) + 
  geom_point()

a %>% 
  ggplot(aes(sbt, centered_numbers)) + 
  geom_point()

a %>% 
  ggplot(aes(delta_sbt, delta_numbers)) + 
  geom_point() + 
  scale_x_continuous(name = "Change in SBT") +
  scale_y_continuous(name = "Change in Numbers")

a %>% 
  ggplot(aes(sbt, fill = factor(patch))) + 
  geom_density(alpha = 0.25)

seen_model <- stan_glm(seen ~ sbt, data = a, family = "binomial") # should have patch as well, but let's keep it simple for now, seems to work well enough
# rstanarm::launch_shinystan(seen_model)
summary(seen_model)
plot(seen_model)

rstanarm::posterior_vs_prior(seen_model)


```


At the moment modeling recruit as temperature driven deviations from mean recruitment. Looking at the patches, I don't think that makes much sense. Let's instead make temperature alter mean recruitment itself, and then allow deviation away from that. 

So, lets say that

$$\bar{r}_{p,y} = Re^{f(t_{p,y})} $$

and then

$$r_{p,y} \sim normal(log(\bar{r}_{p,y}),\sigma_r)$$

So, let's say presence / absence of stage 3 individuals is

$$seen_{p,y} \sim bernoulli(1 + sst_{p,y})$$

If anything is seen...

$$1 \sim bernoulli(1 + sst_{p,y})$$

$$n_{s=3,p,y} \sim NB(\hat{n_{s=3,p,y}} \times sel_{s = 3},\phi) $$

$$pn_{p,y} \sim multinomial(\hat{pn_{p,y} \times sel})$$

else

$$0 \sim bernoulli(1 + sst_{p,y})$$



```{r fit T_dep_rec}

stage_data <- list(
  sel_at_stage = sel_at_stage,
  sst = sbt[, 1:years_train], # this isn't SST anymore, it's SBT... need to rename in model
  sst_proj = sbt[, (years_train):ny],
  spill = spill,
  np = np,
  ns = ns,
  ny = years_train,
  n_p_s_y = pop[,,1:years_train],
  proj_init = pop[,,years_train],
  mean_length_at_age = 1:ns,
  ny_proj = years_proj + 1, 
  m = z,  # should rename model to Z at some point?
  g = g
)

warmups <- 2000

total_iterations <- 4000

max_treedepth <-  12

n_chains <-  4

n_cores <- 4 

stage_model_fit <- stan(file = here::here("src","T_dep_rec_fluke.stan"), # check that it's the right model!
                        data = stage_data,
                        chains = 4,
                        warmup = warmups,
                        iter = total_iterations,
                        cores = 4,
                        refresh = 250,
                        control = list(max_treedepth = max_treedepth,
                                       adapt_delta = 0.95)
)

```

Process results
```{r}

n_p_s_y_hat <-  tidybayes::gather_draws(stage_model_fit, n_p_s_y_hat[patch, stage,year], n = 1000)

n_p_s_y <- pop[,,1:years_train] %>% 
  reshape::melt(varnames = c("patch","stage","year")) %>% 
  as_tibble() 

sel <- tibble(stage = 1:ns, sel = sel_at_stage)

gg_n_p_s_y_hat <- n_p_s_y_hat %>% 
  left_join(sel, by = "stage") %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel, group=stage),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_s_y, aes(x=year, y=value, group=stage), size = 2,alpha = 0.5) + 
  facet_grid(patch~stage, scales = "free_y") + 
  scale_fill_brewer() +
  labs(title="model predictions")

gg_n_p_s_y_hat
gg_n_p_s_y_hat_s3 <- n_p_s_y_hat %>% 
  left_join(sel, by = "stage") %>% 
  filter(stage == 3) %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value * sel, group=stage),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_s_y %>% filter(stage == 3), aes(x=year, y=value, group=stage), size = 2,alpha = 0.5) + 
  facet_wrap(~patch) + 
  scale_fill_brewer() +
  labs(title="model predictions")

gg_n_p_s_y_hat_s3
```


```{r}


pp_proj_n_p_s_y_hat <-  tidybayes::gather_draws(stage_model_fit, pp_proj_n_p_s_y_hat[patch, stage,year], n = 1000)

n_p_s_y_proj <- pop[,,(years_train):ny] %>% 
  reshape::melt(varnames = c("patch","stage","year")) %>% 
  as_tibble() 


gg_pp_proj_n_p_s_y_hat <- pp_proj_n_p_s_y_hat %>% 
  filter(stage == 3) %>% 
  ggplot() +
  stat_lineribbon(aes(x = year, y = .value, group=stage),.width = c(.99, .95, .8, .5), color = "red") +
  geom_point(data = n_p_s_y_proj %>% filter(stage == 3), aes(x=year, y=value, group=stage), size = 2,alpha = 0.5) + 
  facet_wrap(~patch, scales = "free_y") + 
  scale_fill_brewer() +
  labs(title="forecast")

gg_pp_proj_n_p_s_y_hat
```

